---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file).

#4.6 - Lab: Logistic Regression, LDA, QDA, and KNN

##4.6.1 - The Stock Market Data
Today: The current percentage return for current day
Lags(1-5): Previous percentages of past days. 5 being 5 days ago
```{r}
library(ISLR)
names(Smarket)
dim(Smarket)
summary(Smarket)
```
Removing the 9th row
```{r}
cor(Smarket[,-9])
```
Year and volume have the highest correlation
```{r}
attach(Smarket)
plot(Volume)
```
##4.6.2 - Logistic Regression
Use glm fit w/ Lag1-Lag5 and Volume
```{r}
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family=binomial)
summary(glm.fit)
```
```{r}
coef(glm.fit)
summary(glm.fit)$coef
```
Looking at the 'Pr(>|z|)' column
```{r}
summary(glm.fit)$coef[,4]
```
```{r}
glm.probs = predict(glm.fit, type="response")
glm.probs[1:10]
```
Verifying R input dummy variables
```{r}
contrasts(Direction)
```
Make 1250 items vector down. Populate those with > .5 to "Up"
```{r}
glm.pred=rep("Down", 1250)
glm.pred[glm.probs > 0.5] = "Up"
```

```{r}
table(glm.pred, Direction)
mean(glm.pred==Direction)
```
Down down and up up are the correct answers
###Split to train and test
```{r}
train=(Year<2005)
Smarket.2005=Smarket[!train,]
dim(Smarket.2005)
Direction.2005=Direction[!train]
```
There are 252 false observations in the "train" variable
```{r}
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag4+Volume, data=Smarket, family=binomial, subset=train)
glm.probs=predict(glm.fit, Smarket.2005, type="response")
```
We train using "subset" parameter for <2005 dataset. 
```{r}
glm.pred=rep("Down", 252)
glm.pred[glm.probs>.5]="Up"
table(glm.pred, Direction.2005)
```
Worst accuracy here.
```{r}
mean(glm.pred==Direction.2005)
```
Accuracy is 48%, less than random-chance guessing. Accuracy of training set up to 2005 before was 52%.
```{r}
glm.fit=glm(Direction~Lag1+Lag2, data=Smarket, family=binomial, subset=train)
glm.probs=predict(glm.fit, Smarket.2005, type="response")
glm.pred=rep("Down", 252)
glm.pred[glm.probs>.5]="Up"
table(glm.pred, Direction.2005)
mean(glm.pred==Direction.2005)
```
Now we see that using less Lag data by using values w/ low p-value, we can acheive a better prediction

Now we predict on Lag1 and Lag2.
```{r}
predict(glm.fit, newdata = data.frame(Lag1=c(1.2,1.5), Lag2=c(1.1, -0.8)), type="response")
```
Our model gives (1.5, -0.8) a higher percentage of up than (1.2, 1.5) because it put more emphasis on the latest data point

##4.6.3 - Linear Discriminant Analysis
```{r}
library(MASS)
lda.fit=lda(Direction~Lag1+Lag2, daa=Smarket, subset=train)
lda.fit
```
```{r}
plot(lda.fit)
```

